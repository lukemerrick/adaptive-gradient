{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nLoosely based upon training code in https://github.com/xternalz/WideResNet-pytorch\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Loosely based upon training code in https://github.com/xternalz/WideResNet-pytorch\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlp import MLP\n",
    "from average_meter import AverageMeter\n",
    "import time\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, \n",
    "          performance_stats={}, epoch, total_epochs=-1,\n",
    "          verbose=True, print_freq=10\n",
    "          tensorboard_log_function=None,\n",
    "          tensorboard_stats=['train_loss']):\n",
    "    '''\n",
    "    Trains for one epoch. \n",
    "    \n",
    "    x, y are input and target\n",
    "    y_hat is the predicted output\n",
    "    \n",
    "    performance_stats is a dictionary of name:function pairs\n",
    "    where the function calculates some performance score from y and\n",
    "    y_hat\n",
    "    \n",
    "    see the docs for the 'display_training_stats' function for\n",
    "    info on verbose, print_freq, tensorboard_log_function, and\n",
    "    tensorboard_stats\n",
    "    '''\n",
    "    \n",
    "    base_stats = {'time' : AverageMeter(), 'train_loss' : AverageMeter()}\n",
    "    other_stats = {name:AverageMeter() for name in performance_stats.keys()}\n",
    "    stats = {**base_stats, **other_stats}\n",
    "    \n",
    "    # enter training mode\n",
    "    model.train()\n",
    "    \n",
    "    # begin timing the epoch\n",
    "    stopwatch = time.time()\n",
    "    \n",
    "    # iterate over the batches of the epoch\n",
    "    for i, (x, y) in enumerate(train_loader):\n",
    "        y = y.cuda(async=True)\n",
    "        x = x.cuda()\n",
    "        # wrap as Variables\n",
    "        x_var = torch.autograd.Variable(x)\n",
    "        y_var = torch.autograd.Variable(y)\n",
    "        \n",
    "        # forward pass\n",
    "        y_hat = model(x_var)\n",
    "        loss = criterion(y_hat, y_var)\n",
    "        \n",
    "        # track loss and performance stats\n",
    "        stats['train_loss'].update(loss.data[0], x.size(0))\n",
    "        for stat_name, stat_func in performance_stats:\n",
    "            stats[stat_name].update(stat_func(y_hat.data, y), x.size(0))\n",
    "        \n",
    "        # track batch time\n",
    "        stats['batch_time'].update(time.time() - stopwatch)\n",
    "        stopwatch = time.time()\n",
    "        \n",
    "        # display progress\n",
    "        display_training_stats('training', stats, i, len(train_loader), \n",
    "                               epoch, total_epochs, print_results=verbose, \n",
    "                               print_freq=print_freq, \n",
    "                               tensorboard_log_function=tensorboard_log_function,\n",
    "                               tensorboard_stats=tensorboard_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion, epoch, \n",
    "          performance_stats={}, verbose=True, print_freq=10\n",
    "          tensorboard_log_function=None):\n",
    "    '''\n",
    "    Evaluates the model on the validation set.\n",
    "    \n",
    "    x, y are input and target\n",
    "    y_hat is the predicted output\n",
    "    \n",
    "    performance_stats is a dictionary of name:function pairs\n",
    "    where the function calculates some performance score from y and\n",
    "    y_hat\n",
    "    '''\n",
    "    \n",
    "    batch_time = AverageMeter()\n",
    "    losses = AvergeMeter()\n",
    "    stats = {name:AverageMeter() for name in performance_stats.keys()}\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_training_stats(phase, stats, batch, ttl_batches, \n",
    "                           epoch=1, ttl_epochs=1, print_results=True, \n",
    "                           print_freq=10, tensorboard_log_function=None,\n",
    "                           tensorboard_stats=[]):\n",
    "    '''\n",
    "    Handles the logging of training and validation statistics to\n",
    "    printed output and tensorboard.\n",
    "    \n",
    "    phase is a string, typically 'training' or 'validation'\n",
    "    \n",
    "    batch, ttl_batches, epoch, and ttl_epochs are integers indicating\n",
    "    the current epoch & batch and the total number of epochs and batches\n",
    "    \n",
    "    if print_results is True, prints results every print_freq batches\n",
    "    \n",
    "    if tensorboard_log_function is provided, all stats whose names are\n",
    "    passed in the tensorboard_stats list will be logged to tensorboard\n",
    "    using the tensorboard_log_function\n",
    "    '''\n",
    "    \n",
    "    if verbose and (i % print_freq == 0):\n",
    "        msgs = ['{name} {meter.mean:.4f} ({meter.mean:.4f})'.format(\n",
    "                            name=name, meter=meter)\\\n",
    "                            for name, meter in stats.items()]\n",
    "        stats_report = '\\t'.join(msgs)\n",
    "        print('\\{{phase}\\} epoch: [{epoch}/{ttl_epochs}]'\n",
    "              'batch [{batch}/{ttl_batches}]\\n'.format(\n",
    "                  phase=phase, epoch=epoch, ttl_epochs=ttl_epochs,\n",
    "                  batch=batch, ttl_batches=ttl_batches) + stats_report)\n",
    "    \n",
    "    if tensorboard_log_function is not None:\n",
    "        for name in tensorboard_stats:\n",
    "            meter = stats[name]\n",
    "            tensorboard_log_function(name, meter.mean, epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
